{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "iris_ANN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hvx2R3Xj5FU0",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "bdeb4e9b-39f4-4e9f-a14e-b7dac4226486"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d6597dc3-9863-4b6c-b1e6-30f889a1d355\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d6597dc3-9863-4b6c-b1e6-30f889a1d355\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving iris.data to iris.data\n",
            "User uploaded file \"iris.data\" with length 4551 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7k-iq2B5iwW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "31995d3f-c7d8-415d-fcfd-b8ff9437d15f"
      },
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "data = pd.read_csv(io.StringIO(uploaded['iris.data'].decode('utf-8')))\n",
        "data.head(10)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>5.1</th>\n",
              "      <th>3.5</th>\n",
              "      <th>1.4</th>\n",
              "      <th>0.2</th>\n",
              "      <th>Iris-setosa</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.4</td>\n",
              "      <td>3.9</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.4</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.3</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>4.4</td>\n",
              "      <td>2.9</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.1</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>5.4</td>\n",
              "      <td>3.7</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   5.1  3.5  1.4  0.2  Iris-setosa\n",
              "0  4.9  3.0  1.4  0.2  Iris-setosa\n",
              "1  4.7  3.2  1.3  0.2  Iris-setosa\n",
              "2  4.6  3.1  1.5  0.2  Iris-setosa\n",
              "3  5.0  3.6  1.4  0.2  Iris-setosa\n",
              "4  5.4  3.9  1.7  0.4  Iris-setosa\n",
              "5  4.6  3.4  1.4  0.3  Iris-setosa\n",
              "6  5.0  3.4  1.5  0.2  Iris-setosa\n",
              "7  4.4  2.9  1.4  0.2  Iris-setosa\n",
              "8  4.9  3.1  1.5  0.1  Iris-setosa\n",
              "9  5.4  3.7  1.5  0.2  Iris-setosa"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_pcB61F5zsg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = data.iloc[:,:4].values"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYXwmdU959hn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "788a84af-172e-4e91-8c6a-db3a04d08167"
      },
      "source": [
        "import seaborn as sns\n",
        "ax =  sns.countplot(data['Iris-setosa'])\n",
        "print(data['Iris-setosa'].value_counts())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iris-virginica     50\n",
            "Iris-versicolor    50\n",
            "Iris-setosa        49\n",
            "Name: Iris-setosa, dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEGCAYAAABiq/5QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAARx0lEQVR4nO3de7BdZX3G8e9jAkXBW8qRglGDihesinqqKFq5aKW2IlpEHZVoURyrVkbrpdpxrKMd8VoErcZbgkVFVASxpTIoStUCQVECaqEIKgMmXlBD1QL++sd+I4fkJNmErH1y8n4/M2fOWu+6/XLe7Gevvfba705VIUnqx23mugBJ0mQZ/JLUGYNfkjpj8EtSZwx+SerMwrkuYBy77rprLVmyZK7LkKR55YILLvhJVU2t3z4vgn/JkiWsXLlyrsuQpHklyZWztXupR5I6Y/BLUmcMfknqjMEvSZ0x+CWpMwa/JHVm0Ns5k1wB/Aq4EbihqqaTLAJOApYAVwCHV9XPh6xDknSTSZzxH1BV+1TVdJt/DXBWVe0FnNXmJUkTMheXep4MrGjTK4BD56AGSerW0J/cLeALSQp4f1UtA3arqqvb8muA3WbbMMlRwFEAd7/73QcuU9uKH7zxgXNdwnbv7q+/aJD97nfcfoPsVzf56ku/ulX2M3TwP7qqrkpyF+DMJN+dubCqqj0pbKA9SSwDmJ6e9mvCJGkrGfRST1Vd1X6vBk4BHg78OMnuAO336iFrkCTd3GDBn2TnJLdfNw38GbAKOA1Y2lZbCpw6VA2SpA0NealnN+CUJOuO87GqOiPJ+cAnkxwJXAkcvjUP+rBXnrA1d6dZXPC2I+a6BEm3wmDBX1WXAw+epf2nwEFDHVeStGl+cleSOmPwS1JnDH5J6ozBL0mdMfglqTMGvyR1xuCXpM4Y/JLUGYNfkjpj8EtSZwx+SeqMwS9JnTH4JakzBr8kdcbgl6TOGPyS1BmDX5I6Y/BLUmcMfknqjMEvSZ0x+CWpMwa/JHXG4Jekzhj8ktQZg1+SOmPwS1JnDH5J6ozBL0mdMfglqTMGvyR1xuCXpM4Y/JLUmcGDP8mCJN9Mcnqb3zPJuUkuS3JSkh2HrkGSdJNJnPG/DPjOjPljgHdV1b2BnwNHTqAGSVIzaPAnWQz8BfDBNh/gQOBTbZUVwKFD1iBJurmhz/j/GXgV8Ls2/4fAtVV1Q5v/EXDX2TZMclSSlUlWrlmzZuAyJakfgwV/kr8EVlfVBVuyfVUtq6rpqpqempraytVJUr8WDrjv/YBDkjwR2Am4A3AscKckC9tZ/2LgqgFrkCStZ7Az/qr6+6paXFVLgGcAX6yqZwFfAg5rqy0FTh2qBknShubiPv5XAy9Pchmja/4fmoMaJKlbQ17q+b2qOhs4u01fDjx8EseVJG3IT+5KUmcMfknqjMEvSZ0x+CWpMwa/JHXG4Jekzhj8ktQZg1+SOmPwS1JnDH5J6ozBL0mdMfglqTMGvyR1xuCXpM4Y/JLUGYNfkjpj8EtSZwx+SeqMwS9JnTH4JakzBr8kdcbgl6TOGPyS1BmDX5I6Y/BLUmcMfknqjMEvSZ0x+CWpMwa/JHXG4Jekzhj8ktQZg1+SOjNY8CfZKcl5Sb6V5OIk/9ja90xybpLLkpyUZMehapAkbWjIM/7fAgdW1YOBfYCDk+wLHAO8q6ruDfwcOHLAGiRJ6xks+GtkbZvdof0UcCDwqda+Ajh0qBokSRsa9Bp/kgVJLgRWA2cC/wNcW1U3tFV+BNx1yBokSTc3aPBX1Y1VtQ+wGHg4cL9xt01yVJKVSVauWbNmsBolqTcTuaunqq4FvgQ8ErhTkoVt0WLgqo1ss6yqpqtqempqahJlSlIXhryrZyrJndr0bYHHA99h9ARwWFttKXDqUDVIkja0cPOrbLHdgRVJFjB6gvlkVZ2e5BLgE0neBHwT+NCANUiS1jNW8Cc5q6oO2lzbTFX1beAhs7Rfzuh6vyRpDmwy+JPsBNwO2DXJnYG0RXfAu3EkaV7a3Bn/C4GjgT2AC7gp+H8JHD9gXZKkgWwy+KvqWODYJC+tquMmVJMkaUBjXeOvquOSPApYMnObqjphoLokSQMZ983djwL3Ai4EbmzNBRj8kjTPjHs75zSwd1XVkMVIkoY37ge4VgF/NGQhkqTJGPeMf1fgkiTnMRpuGYCqOmSQqiRJgxk3+N8wZBGSpMkZ966eLw9diCRpMsa9q+dXjO7iAdiR0ZeqXFdVdxiqMEnSMMY947/9uukkAZ4M7DtUUZKk4dziYZnbVyp+FnjCAPVIkgY27qWep86YvQ2j+/p/M0hFkqRBjXtXz5NmTN8AXMHoco8kaZ4Z9xr/84YuRJI0GWNd40+yOMkpSVa3n08nWTx0cZKkrW/cN3c/ApzGaFz+PYDPtTZJ0jwzbvBPVdVHquqG9rMcmBqwLknSQMYN/p8meXaSBe3n2cBPhyxMkjSMcYP/r4HDgWuAq4HDgOcOVJMkaUDj3s75RmBpVf0cIMki4O2MnhAkSfPIuGf8D1oX+gBV9TPgIcOUJEka0rjBf5skd1430874x321IEnahowb3u8Avp7k5Db/NODNw5QkSRrSuJ/cPSHJSuDA1vTUqrpkuLIkSUMZ+3JNC3rDXpLmuVs8LLMkaX4z+CWpMwa/JHXG4Jekzhj8ktQZg1+SOjNY8Ce5W5IvJbkkycVJXtbaFyU5M8ml7fedN7cvSdLWM+QZ/w3AK6pqb2Bf4MVJ9gZeA5xVVXsBZ7V5SdKEDBb8VXV1VX2jTf8K+A5wV0Zf0r6irbYCOHSoGiRJG5rINf4kSxiN5nkusFtVXd0WXQPstpFtjkqyMsnKNWvWTKJMSerC4MGfZBfg08DRVfXLmcuqqoCabbuqWlZV01U1PTXltzxK0tYyaPAn2YFR6J9YVZ9pzT9OsntbvjuwesgaJEk3N+RdPQE+BHynqt45Y9FpwNI2vRQ4dagaJEkbGvLLVPYDngNclOTC1vZa4C3AJ5McCVzJ6Lt8JUkTMljwV9V/AtnI4oOGOq4kadP85K4kdcbgl6TOGPyS1BmDX5I6Y/BLUmcMfknqjMEvSZ0x+CWpMwa/JHXG4Jekzhj8ktQZg1+SOmPwS1JnDH5J6ozBL0mdMfglqTMGvyR1xuCXpM4Y/JLUGYNfkjpj8EtSZwx+SeqMwS9JnTH4JakzBr8kdcbgl6TOGPyS1BmDX5I6Y/BLUmcMfknqjMEvSZ0x+CWpM4MFf5IPJ1mdZNWMtkVJzkxyaft956GOL0ma3ZBn/MuBg9drew1wVlXtBZzV5iVJEzRY8FfVV4Cfrdf8ZGBFm14BHDrU8SVJs5v0Nf7dqurqNn0NsNvGVkxyVJKVSVauWbNmMtVJUgfm7M3dqiqgNrF8WVVNV9X01NTUBCuTpO3bpIP/x0l2B2i/V0/4+JLUvUkH/2nA0ja9FDh1wseXpO4NeTvnx4GvA/dN8qMkRwJvAR6f5FLgcW1ekjRBC4facVU9cyOLDhrqmJKkzfOTu5LUGYNfkjpj8EtSZwx+SeqMwS9JnTH4JakzBr8kdcbgl6TOGPyS1BmDX5I6Y/BLUmcMfknqjMEvSZ0x+CWpMwa/JHXG4Jekzhj8ktQZg1+SOmPwS1JnDH5J6ozBL0mdMfglqTMGvyR1xuCXpM4Y/JLUGYNfkjpj8EtSZwx+SeqMwS9JnTH4JakzBr8kdcbgl6TOGPyS1Jk5Cf4kByf5XpLLkrxmLmqQpF5NPPiTLADeA/w5sDfwzCR7T7oOSerVXJzxPxy4rKour6r/Az4BPHkO6pCkLqWqJnvA5DDg4Kp6fpt/DvCIqnrJeusdBRzVZu8LfG+ihU7WrsBP5roIbRH7bn7b3vvvHlU1tX7jwrmoZBxVtQxYNtd1TEKSlVU1Pdd16Jaz7+a3XvtvLi71XAXcbcb84tYmSZqAuQj+84G9kuyZZEfgGcBpc1CHJHVp4pd6quqGJC8B/gNYAHy4qi6edB3bmC4uaW2n7Lv5rcv+m/ibu5KkueUndyWpMwa/JHXG4N+MJGs3sexrAx73tUPte3syV/0zjiR7JPnUFm57dpJubjMcuh+TvDHJ427hNodsbkiZW9PHc8lr/JuRZG1V7bJe28KqumHSx9WG5qp/hj5ekrOBv6uqlWOuv6CqbtyaNUzSHD7O5vXfbUt5xj+mJPsnOSfJacAlrW1t+717kq8kuTDJqiSPmWX7ByQ5r63z7SR7tfZnz2h/f5IFSd4C3La1ndjWe3nb96okR7e2nZN8Psm3WvvTW/vrk5zf2pYlyWT+SnPn1vRPkjsmuTLJbdr8zkl+mGSHJPdKckaSC9r+79fWWZ7kfUnOBd6a5LFt/xcm+WaS2ydZkmRVW39Bkre34387yUtb+0Ft/YuSfDjJH8zyb3tmW74qyTEz2tcmeUeSbwGPHOQPO2ED9uPyjEYNIMkVSY5J8g3gaUmemOS7rY/fneT0tt5zkxzfppe3ZV9LcvmMfY3Tx9ve47Gq/NnED7C2/d4fuA7Yc5ZlrwBe16YXALefZT/HAc9q0zsCtwXuD3wO2KG1vxc4Yua+2/TDgIuAnYFdgIuBhwB/BXxgxnp3bL8XzWj7KPCkuf47zoP+ORU4oE0/Hfhgmz4L2KtNPwL4YpteDpwOLGjznwP2a9O7MLpVegmwqrW9CPgUsHBdHwE7AT8E7tPaTgCObtNnA9PAHsAPgKm2zy8Ch7Z1Cjh8rvtgnvTjcuCwNn0F8Ko2va4P9mzzHwdOb9PPBY6fsf3JjE6W92Y03hib6+OZv9v0NvF49Iz/ljmvqr4/S/v5wPOSvAF4YFX9apZ1vg68NsmrGY2f8WvgIEahfn6SC9v8PWfZ9tHAKVV1XVWtBT4DPIbRk8Hj29nLY6rqF239A5Kcm+Qi4EDgAVv8L55fbk3/nMQoKGD0ocKTkuwCPAo4ufXP+4HdZ2xzct10meCrwDuT/C1wp9rwEsXjgPeva6+qnzEag+r7VfXfbZ0VwJ+ut92fAGdX1Zq27Ykz1rkR+PRsf4h5bqv240aOsa79fsDlM4738U3U9dmq+l1VXQLsNsvy2foYtsHHo8F/y1w3W2NVfYXRg/EqYHmSI5I8ZcZL/+mq+hhwCPBr4N+SHAgEWFFV+7Sf+1bVG8YtpgXGQxk9AbypvaTcidErh8Oq6oHABxid1fRgi/uH0afHD06yiNGT8RcZPT6undE/+1TV/Wc7XlW9BXg+o1dyX113SWhgv6nt8/r01u7HsY+xGb+dMT3W5Zpt9fFo8G8FSe4B/LiqPgB8EHhoVZ0yIyxWJrknozOLdzN6OfogRpcRDktyl7afRW1fANcn2aFNnwMcmuR2SXYGngKck2QP4H+r6l+BtzF6Elj3n+on7Yz1sMH/ANu4cfqnvZI6HziW0Uv9G6vql8D3kzyt7SdJHryRY9yrqi6qqmPaftYP/jOBFyZZ2NZfxGjE2SVJ7t3WeQ7w5fW2Ow94bJJdM/oui2fOsk4XtrQfN7Pb7wH3TLKkzT9946tu1mx9vE0+HrfZ0Tnnmf2BVya5HlgLHDHLOocDz2nrXAP8U1X9LMk/AF9ob0hdD7wYuJLRR8m/neQbVfWsJMsZhQCMrlt+M8kTgLcl+V3b9kVVdW2SDwCr2nHOH+jfPJ/sz+b7B0Yv/09u66/zLOBfWj/twOj7I741y7ZHJzkA+B2j92D+nZtfFvogcB9GfXo9o/dmjk/yPEaXkhYy6qv3zdxpVV2d0S2FX2J0lvn5qjp13H/4dmZ/trwfZ1VVv07yN8AZSa7j1j1eNtbH29zj0ds5JXUtyS5VtbbdbfMe4NKqetdc1zUkL/VI6t0L2pv3FwN3ZPQm/nbNM35J6oxn/JLUGYNfkjpj8EtSZwx+bdfi6KrSBnxzV9u1OLqqtAHP+NWFOLqq9Hue8Wu7tu7MO8n+wOeBP143INeMZa8AdqqqN7dhEW63/gBgSY4D/quqTkyyI6PRIZcAbwWeWlXXJ3lvW+eEmWf8SR7GaHTHfRl9+vZc4NmMBuQ7uKpe0Na7Y1X9IsmidQN8Jfko8Mmq+tyAfyZ1xiEb1JNNjfr44TY20mer6sJZ1vk68Loki4HPVNWlSWaOrgqjAdpWz7Lt70dXBUiybnTVM4B3ZDTG/ulVdU5b/4AkrwJux2j45osZDfssbRVe6lFPHF1VwuCXHF1V3fFSj+ToquqMb+5KUme81CNJnTH4JakzBr8kdcbgl6TOGPyS1BmDX5I6Y/BLUmf+H8QC7MnpQmA3AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WFWJAD-6NxI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikOqoMET6TIQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y =  data.iloc[: ,4].values\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "labelEncoder = LabelEncoder()\n",
        "y1 = labelEncoder.fit_transform(Y)\n",
        "Y = pd.get_dummies(y1).values"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WRSbNYc6dQZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "74b71e71-0dce-4f4e-b272-43a82d0e88db"
      },
      "source": [
        "Y"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyUwJhoe6fhY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.30,random_state=0)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler=StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.fit_transform(X_test)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36x4mf6o6n2g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "22299f90-8e51-43a2-93e2-620aa9de071b"
      },
      "source": [
        "X_train"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.84458245,  0.76054343, -1.39462947, -1.37310134],\n",
              "       [-0.96820522, -1.29638085, -0.48118795, -0.19285131],\n",
              "       [ 0.39164525, -0.38219228,  0.26098329,  0.06942647],\n",
              "       [ 0.02077694,  0.30344915,  0.54643377,  0.72512093],\n",
              "       [-0.96820522,  1.674732  , -1.33753937, -1.24196244],\n",
              "       [-1.21545076, -1.29638085,  0.37516348,  0.59398204],\n",
              "       [ 0.63889079,  0.074902  ,  0.94606443,  0.72512093],\n",
              "       [ 0.14439971, -1.98202227,  0.08971301, -0.3239902 ],\n",
              "       [ 1.25700463,  0.074902  ,  0.60352386,  0.33170426],\n",
              "       [-1.58631907,  0.074902  , -1.33753937, -1.37310134],\n",
              "       [ 0.76251356, -0.15364514,  0.77479415,  0.98739871],\n",
              "       [-1.33907353,  0.76054343, -1.28044928, -1.37310134],\n",
              "       [-1.21545076, -1.52492799, -0.30991766, -0.3239902 ],\n",
              "       [-0.10284583, -0.61073942,  0.71770405,  1.51195428],\n",
              "       [ 1.00975909,  0.53199629,  1.06024462,  1.64309317],\n",
              "       [ 2.24598679,  1.674732  ,  1.63114558,  1.2496765 ],\n",
              "       [-0.10284583, -0.83928656,  0.1468031 , -0.3239902 ],\n",
              "       [-0.2264686 , -1.06783371, -0.19573747, -0.3239902 ],\n",
              "       [ 0.51526802, -1.29638085,  0.60352386,  0.33170426],\n",
              "       [ 0.63889079, -0.61073942,  1.00315453,  1.2496765 ],\n",
              "       [-0.35009137, -0.61073942,  0.60352386,  0.98739871],\n",
              "       [-0.47371414, -1.06783371,  0.31807339, -0.06171242],\n",
              "       [ 0.51526802, -1.29638085,  0.66061396,  0.85625982],\n",
              "       [-0.10284583, -0.83928656,  0.71770405,  0.85625982],\n",
              "       [ 0.63889079,  0.30344915,  0.37516348,  0.33170426],\n",
              "       [ 0.26802248, -0.15364514,  0.60352386,  0.72512093],\n",
              "       [ 0.02077694, -0.15364514,  0.2038932 ,  0.33170426],\n",
              "       [-0.59733691,  0.76054343, -1.33753937, -1.11082355],\n",
              "       [-0.35009137, -0.38219228, -0.13864737,  0.06942647],\n",
              "       [-0.10284583, -1.06783371,  0.08971301, -0.06171242],\n",
              "       [-0.59733691, -0.15364514,  0.37516348,  0.33170426],\n",
              "       [ 0.51526802, -1.75347513,  0.31807339,  0.06942647],\n",
              "       [ 1.00975909,  0.53199629,  1.06024462,  1.11853761],\n",
              "       [-0.2264686 , -0.61073942,  0.1468031 ,  0.06942647],\n",
              "       [ 0.51526802, -0.83928656,  0.60352386,  0.72512093],\n",
              "       [-1.09182799,  0.53199629, -1.39462947, -1.37310134],\n",
              "       [-0.10284583,  2.13182628, -1.50880966, -1.37310134],\n",
              "       [ 1.62787294,  1.21763771,  1.28860501,  1.64309317],\n",
              "       [-1.09182799, -1.75347513, -0.30991766, -0.3239902 ],\n",
              "       [-0.96820522,  1.44618486, -1.33753937, -1.11082355],\n",
              "       [-0.59733691,  1.90327914, -1.45171956, -1.11082355],\n",
              "       [-0.47371414, -1.75347513,  0.08971301,  0.06942647],\n",
              "       [-1.09182799,  1.21763771, -1.39462947, -1.37310134],\n",
              "       [ 0.63889079, -0.61073942,  1.00315453,  1.11853761],\n",
              "       [ 1.00975909, -0.15364514,  0.66061396,  0.59398204],\n",
              "       [-1.09182799,  0.76054343, -1.33753937, -1.37310134],\n",
              "       [-0.35009137, -1.29638085,  0.03262291, -0.19285131],\n",
              "       [ 1.75149571, -0.38219228,  1.4027852 ,  0.72512093],\n",
              "       [-0.35009137, -0.83928656,  0.2038932 ,  0.06942647],\n",
              "       [-1.95718738, -0.15364514, -1.56589975, -1.50424023],\n",
              "       [ 1.62787294,  0.30344915,  1.23151491,  0.72512093],\n",
              "       [ 0.39164525,  0.76054343,  0.88897434,  1.38081539],\n",
              "       [ 1.50425017, -0.15364514,  1.17442482,  1.11853761],\n",
              "       [ 0.39164525, -0.61073942,  0.54643377,  0.72512093],\n",
              "       [-1.58631907,  0.30344915, -1.39462947, -1.37310134],\n",
              "       [-1.33907353, -0.15364514, -1.39462947, -1.50424023],\n",
              "       [ 1.00975909, -1.29638085,  1.11733472,  0.72512093],\n",
              "       [-0.2264686 , -1.29638085,  0.66061396,  0.98739871],\n",
              "       [-1.83356461,  0.30344915, -1.45171956, -1.37310134],\n",
              "       [ 0.63889079,  0.30344915,  0.83188424,  1.38081539],\n",
              "       [-1.4626963 ,  0.30344915, -1.45171956, -1.37310134],\n",
              "       [ 0.63889079, -0.83928656,  0.83188424,  0.85625982],\n",
              "       [ 1.25700463,  0.074902  ,  0.88897434,  1.11853761],\n",
              "       [-1.09182799,  0.98909057, -1.28044928, -0.84854577],\n",
              "       [-0.59733691,  1.90327914, -1.22335918, -1.11082355],\n",
              "       [ 1.62787294, -0.15364514,  1.11733472,  0.46284315],\n",
              "       [-0.2264686 ,  1.674732  , -1.22335918, -1.24196244],\n",
              "       [-0.96820522,  0.76054343, -1.33753937, -1.37310134],\n",
              "       [-1.58631907,  0.76054343, -1.39462947, -1.24196244],\n",
              "       [ 0.76251356, -0.61073942,  0.43225358,  0.33170426],\n",
              "       [ 1.13338186,  0.30344915,  1.17442482,  1.38081539],\n",
              "       [ 0.51526802, -0.38219228,  1.00315453,  0.72512093],\n",
              "       [-1.21545076, -0.15364514, -1.39462947, -1.37310134],\n",
              "       [-1.09182799,  0.30344915, -1.50880966, -1.37310134],\n",
              "       [-1.4626963 ,  0.30344915, -1.28044928, -1.37310134],\n",
              "       [ 0.51526802,  0.53199629,  0.48934367,  0.46284315],\n",
              "       [ 1.13338186, -0.61073942,  0.54643377,  0.20056536],\n",
              "       [-0.47371414,  0.98909057, -1.45171956, -1.37310134],\n",
              "       [-1.33907353,  0.76054343, -1.10917899, -1.37310134],\n",
              "       [ 0.88613632, -0.15364514,  0.31807339,  0.20056536],\n",
              "       [-0.84458245,  2.36037342, -1.33753937, -1.50424023],\n",
              "       [ 2.24598679, -0.61073942,  1.63114558,  0.98739871],\n",
              "       [ 0.88613632, -0.38219228,  0.43225358,  0.06942647],\n",
              "       [ 2.49323233,  1.674732  ,  1.45987529,  0.98739871],\n",
              "       [-0.35009137, -0.15364514,  0.37516348,  0.33170426],\n",
              "       [-0.47371414,  2.58892057, -1.39462947, -1.37310134],\n",
              "       [ 0.14439971, -0.15364514,  0.54643377,  0.72512093],\n",
              "       [-0.2264686 ,  3.04601485, -1.33753937, -1.11082355],\n",
              "       [ 1.25700463,  0.30344915,  1.06024462,  1.38081539],\n",
              "       [-0.59733691,  0.76054343, -1.22335918, -1.37310134],\n",
              "       [-1.33907353,  0.074902  , -1.28044928, -1.37310134],\n",
              "       [ 1.87511848, -0.61073942,  1.28860501,  0.85625982],\n",
              "       [ 1.3806274 ,  0.30344915,  0.48934367,  0.20056536],\n",
              "       [ 0.51526802,  0.76054343,  1.00315453,  1.51195428],\n",
              "       [ 0.51526802,  0.53199629,  1.23151491,  1.64309317],\n",
              "       [ 0.14439971, -0.83928656,  0.71770405,  0.46284315],\n",
              "       [ 1.00975909,  0.074902  ,  0.31807339,  0.20056536],\n",
              "       [ 0.02077694, -0.15364514,  0.71770405,  0.72512093],\n",
              "       [-0.47371414, -1.52492799, -0.02446718, -0.19285131],\n",
              "       [ 0.76251356, -0.15364514,  0.94606443,  0.72512093],\n",
              "       [ 1.00975909, -0.15364514,  0.77479415,  1.38081539],\n",
              "       [ 0.26802248, -0.61073942,  0.48934367, -0.06171242],\n",
              "       [ 0.14439971, -0.38219228,  0.37516348,  0.33170426],\n",
              "       [-1.09182799,  0.76054343, -1.28044928, -1.11082355],\n",
              "       [-0.10284583, -0.83928656,  0.03262291, -0.06171242],\n",
              "       [ 1.00975909,  0.074902  ,  1.00315453,  1.51195428],\n",
              "       [-0.10284583, -0.83928656,  0.71770405,  0.85625982],\n",
              "       [-1.09182799,  0.98909057, -1.45171956, -1.24196244],\n",
              "       [-0.84458245, -0.83928656,  0.03262291,  0.20056536],\n",
              "       [-0.47371414, -1.29638085,  0.08971301,  0.06942647],\n",
              "       [ 0.26802248, -0.61073942,  0.08971301,  0.06942647],\n",
              "       [-0.35009137, -0.15364514,  0.1468031 ,  0.06942647],\n",
              "       [-1.21545076,  0.074902  , -1.33753937, -1.50424023],\n",
              "       [-1.58631907,  1.21763771, -1.62298985, -1.37310134],\n",
              "       [-0.59733691,  1.44618486, -1.33753937, -1.37310134],\n",
              "       [ 0.76251356, -0.15364514,  1.11733472,  1.2496765 ],\n",
              "       [ 0.39164525, -1.98202227,  0.37516348,  0.33170426],\n",
              "       [ 2.24598679, -1.06783371,  1.74532577,  1.38081539],\n",
              "       [-0.72095968,  1.44618486, -1.33753937, -1.37310134]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQRCNJ-O6xGH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7b5701f2-d4e3-4c31-d6ad-04368c745626"
      },
      "source": [
        "Y_train"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [1, 0, 0],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [1, 0, 0],\n",
              "       [0, 0, 1],\n",
              "       [1, 0, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 1, 0],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 1, 0],\n",
              "       [0, 0, 1],\n",
              "       [0, 1, 0],\n",
              "       [1, 0, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 0, 1],\n",
              "       [0, 1, 0],\n",
              "       [0, 0, 1],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [0, 0, 1],\n",
              "       [0, 1, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [0, 1, 0],\n",
              "       [1, 0, 0],\n",
              "       [0, 0, 1],\n",
              "       [0, 1, 0],\n",
              "       [1, 0, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 0, 1],\n",
              "       [0, 1, 0],\n",
              "       [1, 0, 0],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [1, 0, 0],\n",
              "       [0, 0, 1],\n",
              "       [1, 0, 0],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [0, 0, 1],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [0, 1, 0],\n",
              "       [1, 0, 0],\n",
              "       [0, 0, 1],\n",
              "       [0, 1, 0],\n",
              "       [0, 0, 1],\n",
              "       [0, 1, 0],\n",
              "       [1, 0, 0],\n",
              "       [0, 0, 1],\n",
              "       [1, 0, 0],\n",
              "       [0, 0, 1],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [0, 0, 1],\n",
              "       [0, 1, 0],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 0, 1],\n",
              "       [0, 1, 0],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [1, 0, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [1, 0, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [0, 0, 1],\n",
              "       [0, 1, 0],\n",
              "       [0, 0, 1],\n",
              "       [1, 0, 0]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWtE0_Rh6zBy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "291d7667-97d6-4751-dc1b-579f78b0d26b"
      },
      "source": [
        "!pip install keras\n",
        "import keras\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.3.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.18.5)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras) (1.1.2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcJm_Eix67qP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(4,input_shape=(4,),activation=\"relu\"))\n",
        "model.add(Dense(3,activation=\"softmax\"))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vp13M_pu8TWS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=\"Adam\",loss=\"categorical_crossentropy\",metrics=['accuracy'])"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Xc4gGWV8sXT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "d942127e-60b1-4c46-b46c-16ed4efc6984"
      },
      "source": [
        "model.weights"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'dense_2/kernel:0' shape=(4, 4) dtype=float32, numpy=\n",
              " array([[-0.70289403,  0.4446227 , -0.4036311 ,  0.80568963],\n",
              "        [-0.84774005, -0.73851126,  0.8243051 ,  0.04872972],\n",
              "        [-0.5054604 ,  0.46560186, -0.6806532 ,  0.16052371],\n",
              "        [ 0.19236702, -0.77160096, -0.66360986, -0.06619143]],\n",
              "       dtype=float32)>,\n",
              " <tf.Variable 'dense_2/bias:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>,\n",
              " <tf.Variable 'dense_3/kernel:0' shape=(4, 3) dtype=float32, numpy=\n",
              " array([[-0.24944472,  0.6403129 , -0.29399657],\n",
              "        [ 0.20786929, -0.5625274 , -0.18430984],\n",
              "        [ 0.78618085,  0.3628323 , -0.27406925],\n",
              "        [-0.45952335, -0.60910267,  0.23430228]], dtype=float32)>,\n",
              " <tf.Variable 'dense_3/bias:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hq7lYK2K8w2J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "baf0a214-6ac1-44e7-9083-3687b5334878"
      },
      "source": [
        "model.fit(X_train,Y_train,batch_size=20,nb_epoch=200)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "104/104 [==============================] - 0s 130us/step - loss: 0.0250 - accuracy: 1.0000\n",
            "Epoch 2/200\n",
            "104/104 [==============================] - 0s 94us/step - loss: 0.0249 - accuracy: 1.0000\n",
            "Epoch 3/200\n",
            "104/104 [==============================] - 0s 91us/step - loss: 0.0249 - accuracy: 1.0000\n",
            "Epoch 4/200\n",
            "104/104 [==============================] - 0s 97us/step - loss: 0.0247 - accuracy: 1.0000\n",
            "Epoch 5/200\n",
            "104/104 [==============================] - 0s 89us/step - loss: 0.0245 - accuracy: 1.0000\n",
            "Epoch 6/200\n",
            "104/104 [==============================] - 0s 99us/step - loss: 0.0244 - accuracy: 1.0000\n",
            "Epoch 7/200\n",
            "104/104 [==============================] - 0s 100us/step - loss: 0.0246 - accuracy: 1.0000\n",
            "Epoch 8/200\n",
            "104/104 [==============================] - 0s 98us/step - loss: 0.0243 - accuracy: 1.0000\n",
            "Epoch 9/200\n",
            "104/104 [==============================] - 0s 88us/step - loss: 0.0240 - accuracy: 1.0000\n",
            "Epoch 10/200\n",
            "104/104 [==============================] - 0s 89us/step - loss: 0.0243 - accuracy: 1.0000\n",
            "Epoch 11/200\n",
            "104/104 [==============================] - 0s 84us/step - loss: 0.0237 - accuracy: 0.9904\n",
            "Epoch 12/200\n",
            "104/104 [==============================] - 0s 90us/step - loss: 0.0237 - accuracy: 0.9904\n",
            "Epoch 13/200\n",
            "104/104 [==============================] - 0s 86us/step - loss: 0.0237 - accuracy: 0.9904\n",
            "Epoch 14/200\n",
            "104/104 [==============================] - 0s 89us/step - loss: 0.0237 - accuracy: 0.9904\n",
            "Epoch 15/200\n",
            "104/104 [==============================] - 0s 100us/step - loss: 0.0235 - accuracy: 0.9904\n",
            "Epoch 16/200\n",
            "104/104 [==============================] - 0s 92us/step - loss: 0.0235 - accuracy: 0.9904\n",
            "Epoch 17/200\n",
            "104/104 [==============================] - 0s 101us/step - loss: 0.0233 - accuracy: 0.9904\n",
            "Epoch 18/200\n",
            " 20/104 [====>.........................] - ETA: 0s - loss: 0.0106 - accuracy: 1.0000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "104/104 [==============================] - 0s 89us/step - loss: 0.0232 - accuracy: 0.9904\n",
            "Epoch 19/200\n",
            "104/104 [==============================] - 0s 95us/step - loss: 0.0231 - accuracy: 0.9904\n",
            "Epoch 20/200\n",
            "104/104 [==============================] - 0s 102us/step - loss: 0.0230 - accuracy: 0.9904\n",
            "Epoch 21/200\n",
            "104/104 [==============================] - 0s 101us/step - loss: 0.0230 - accuracy: 0.9904\n",
            "Epoch 22/200\n",
            "104/104 [==============================] - 0s 89us/step - loss: 0.0227 - accuracy: 1.0000\n",
            "Epoch 23/200\n",
            "104/104 [==============================] - 0s 99us/step - loss: 0.0230 - accuracy: 1.0000\n",
            "Epoch 24/200\n",
            "104/104 [==============================] - 0s 85us/step - loss: 0.0229 - accuracy: 1.0000\n",
            "Epoch 25/200\n",
            "104/104 [==============================] - 0s 87us/step - loss: 0.0229 - accuracy: 1.0000\n",
            "Epoch 26/200\n",
            "104/104 [==============================] - 0s 90us/step - loss: 0.0228 - accuracy: 1.0000\n",
            "Epoch 27/200\n",
            "104/104 [==============================] - 0s 88us/step - loss: 0.0228 - accuracy: 1.0000\n",
            "Epoch 28/200\n",
            "104/104 [==============================] - 0s 110us/step - loss: 0.0229 - accuracy: 1.0000\n",
            "Epoch 29/200\n",
            "104/104 [==============================] - 0s 104us/step - loss: 0.0226 - accuracy: 1.0000\n",
            "Epoch 30/200\n",
            "104/104 [==============================] - 0s 88us/step - loss: 0.0226 - accuracy: 1.0000\n",
            "Epoch 31/200\n",
            "104/104 [==============================] - 0s 88us/step - loss: 0.0223 - accuracy: 0.9904\n",
            "Epoch 32/200\n",
            "104/104 [==============================] - 0s 90us/step - loss: 0.0225 - accuracy: 0.9904\n",
            "Epoch 33/200\n",
            "104/104 [==============================] - 0s 81us/step - loss: 0.0224 - accuracy: 0.9904\n",
            "Epoch 34/200\n",
            "104/104 [==============================] - 0s 88us/step - loss: 0.0224 - accuracy: 0.9904\n",
            "Epoch 35/200\n",
            "104/104 [==============================] - 0s 87us/step - loss: 0.0223 - accuracy: 0.9904\n",
            "Epoch 36/200\n",
            "104/104 [==============================] - 0s 88us/step - loss: 0.0222 - accuracy: 0.9904\n",
            "Epoch 37/200\n",
            "104/104 [==============================] - 0s 111us/step - loss: 0.0221 - accuracy: 0.9904\n",
            "Epoch 38/200\n",
            "104/104 [==============================] - 0s 90us/step - loss: 0.0221 - accuracy: 0.9904\n",
            "Epoch 39/200\n",
            "104/104 [==============================] - 0s 106us/step - loss: 0.0220 - accuracy: 0.9904\n",
            "Epoch 40/200\n",
            "104/104 [==============================] - 0s 92us/step - loss: 0.0220 - accuracy: 0.9904\n",
            "Epoch 41/200\n",
            "104/104 [==============================] - 0s 86us/step - loss: 0.0219 - accuracy: 0.9904\n",
            "Epoch 42/200\n",
            "104/104 [==============================] - 0s 91us/step - loss: 0.0219 - accuracy: 0.9904\n",
            "Epoch 43/200\n",
            "104/104 [==============================] - 0s 87us/step - loss: 0.0220 - accuracy: 0.9904\n",
            "Epoch 44/200\n",
            "104/104 [==============================] - 0s 101us/step - loss: 0.0227 - accuracy: 0.9904\n",
            "Epoch 45/200\n",
            "104/104 [==============================] - 0s 102us/step - loss: 0.0221 - accuracy: 1.0000\n",
            "Epoch 46/200\n",
            "104/104 [==============================] - 0s 94us/step - loss: 0.0222 - accuracy: 1.0000\n",
            "Epoch 47/200\n",
            "104/104 [==============================] - 0s 88us/step - loss: 0.0221 - accuracy: 1.0000\n",
            "Epoch 48/200\n",
            "104/104 [==============================] - 0s 98us/step - loss: 0.0222 - accuracy: 1.0000\n",
            "Epoch 49/200\n",
            "104/104 [==============================] - 0s 96us/step - loss: 0.0223 - accuracy: 1.0000\n",
            "Epoch 50/200\n",
            "104/104 [==============================] - 0s 82us/step - loss: 0.0222 - accuracy: 1.0000\n",
            "Epoch 51/200\n",
            "104/104 [==============================] - 0s 80us/step - loss: 0.0222 - accuracy: 1.0000\n",
            "Epoch 52/200\n",
            "104/104 [==============================] - 0s 83us/step - loss: 0.0220 - accuracy: 1.0000\n",
            "Epoch 53/200\n",
            "104/104 [==============================] - 0s 86us/step - loss: 0.0220 - accuracy: 1.0000\n",
            "Epoch 54/200\n",
            "104/104 [==============================] - 0s 154us/step - loss: 0.0219 - accuracy: 1.0000\n",
            "Epoch 55/200\n",
            "104/104 [==============================] - 0s 88us/step - loss: 0.0219 - accuracy: 1.0000\n",
            "Epoch 56/200\n",
            "104/104 [==============================] - 0s 86us/step - loss: 0.0217 - accuracy: 1.0000\n",
            "Epoch 57/200\n",
            "104/104 [==============================] - 0s 85us/step - loss: 0.0217 - accuracy: 1.0000\n",
            "Epoch 58/200\n",
            "104/104 [==============================] - 0s 90us/step - loss: 0.0215 - accuracy: 1.0000\n",
            "Epoch 59/200\n",
            "104/104 [==============================] - 0s 114us/step - loss: 0.0215 - accuracy: 1.0000\n",
            "Epoch 60/200\n",
            "104/104 [==============================] - 0s 99us/step - loss: 0.0214 - accuracy: 1.0000\n",
            "Epoch 61/200\n",
            "104/104 [==============================] - 0s 105us/step - loss: 0.0214 - accuracy: 1.0000\n",
            "Epoch 62/200\n",
            "104/104 [==============================] - 0s 98us/step - loss: 0.0213 - accuracy: 0.9904\n",
            "Epoch 63/200\n",
            "104/104 [==============================] - 0s 98us/step - loss: 0.0213 - accuracy: 0.9904\n",
            "Epoch 64/200\n",
            "104/104 [==============================] - 0s 89us/step - loss: 0.0213 - accuracy: 0.9904\n",
            "Epoch 65/200\n",
            "104/104 [==============================] - 0s 123us/step - loss: 0.0212 - accuracy: 0.9904\n",
            "Epoch 66/200\n",
            "104/104 [==============================] - 0s 101us/step - loss: 0.0212 - accuracy: 0.9904\n",
            "Epoch 67/200\n",
            "104/104 [==============================] - 0s 92us/step - loss: 0.0212 - accuracy: 0.9904\n",
            "Epoch 68/200\n",
            "104/104 [==============================] - 0s 93us/step - loss: 0.0213 - accuracy: 0.9904\n",
            "Epoch 69/200\n",
            "104/104 [==============================] - 0s 96us/step - loss: 0.0212 - accuracy: 0.9904\n",
            "Epoch 70/200\n",
            "104/104 [==============================] - 0s 113us/step - loss: 0.0211 - accuracy: 0.9904\n",
            "Epoch 71/200\n",
            "104/104 [==============================] - 0s 101us/step - loss: 0.0211 - accuracy: 0.9904\n",
            "Epoch 72/200\n",
            "104/104 [==============================] - 0s 92us/step - loss: 0.0211 - accuracy: 0.9904\n",
            "Epoch 73/200\n",
            "104/104 [==============================] - 0s 98us/step - loss: 0.0211 - accuracy: 0.9904\n",
            "Epoch 74/200\n",
            "104/104 [==============================] - 0s 87us/step - loss: 0.0210 - accuracy: 0.9904\n",
            "Epoch 75/200\n",
            "104/104 [==============================] - 0s 80us/step - loss: 0.0210 - accuracy: 0.9904\n",
            "Epoch 76/200\n",
            "104/104 [==============================] - 0s 84us/step - loss: 0.0210 - accuracy: 0.9904\n",
            "Epoch 77/200\n",
            "104/104 [==============================] - 0s 82us/step - loss: 0.0210 - accuracy: 0.9904\n",
            "Epoch 78/200\n",
            "104/104 [==============================] - 0s 88us/step - loss: 0.0211 - accuracy: 0.9904\n",
            "Epoch 79/200\n",
            "104/104 [==============================] - 0s 89us/step - loss: 0.0210 - accuracy: 0.9904\n",
            "Epoch 80/200\n",
            "104/104 [==============================] - 0s 113us/step - loss: 0.0209 - accuracy: 0.9904\n",
            "Epoch 81/200\n",
            "104/104 [==============================] - 0s 85us/step - loss: 0.0209 - accuracy: 0.9904\n",
            "Epoch 82/200\n",
            "104/104 [==============================] - 0s 103us/step - loss: 0.0209 - accuracy: 0.9904\n",
            "Epoch 83/200\n",
            "104/104 [==============================] - 0s 100us/step - loss: 0.0210 - accuracy: 0.9904\n",
            "Epoch 84/200\n",
            "104/104 [==============================] - 0s 87us/step - loss: 0.0209 - accuracy: 0.9904\n",
            "Epoch 85/200\n",
            "104/104 [==============================] - 0s 85us/step - loss: 0.0209 - accuracy: 0.9904\n",
            "Epoch 86/200\n",
            "104/104 [==============================] - 0s 110us/step - loss: 0.0209 - accuracy: 0.9904\n",
            "Epoch 87/200\n",
            "104/104 [==============================] - 0s 85us/step - loss: 0.0206 - accuracy: 0.9904\n",
            "Epoch 88/200\n",
            "104/104 [==============================] - 0s 86us/step - loss: 0.0208 - accuracy: 0.9904\n",
            "Epoch 89/200\n",
            "104/104 [==============================] - 0s 89us/step - loss: 0.0208 - accuracy: 1.0000\n",
            "Epoch 90/200\n",
            "104/104 [==============================] - 0s 76us/step - loss: 0.0213 - accuracy: 1.0000\n",
            "Epoch 91/200\n",
            "104/104 [==============================] - 0s 74us/step - loss: 0.0212 - accuracy: 1.0000\n",
            "Epoch 92/200\n",
            "104/104 [==============================] - 0s 103us/step - loss: 0.0211 - accuracy: 1.0000\n",
            "Epoch 93/200\n",
            "104/104 [==============================] - 0s 90us/step - loss: 0.0209 - accuracy: 1.0000\n",
            "Epoch 94/200\n",
            "104/104 [==============================] - 0s 93us/step - loss: 0.0205 - accuracy: 1.0000\n",
            "Epoch 95/200\n",
            "104/104 [==============================] - 0s 82us/step - loss: 0.0208 - accuracy: 0.9904\n",
            "Epoch 96/200\n",
            "104/104 [==============================] - 0s 90us/step - loss: 0.0206 - accuracy: 0.9904\n",
            "Epoch 97/200\n",
            "104/104 [==============================] - 0s 95us/step - loss: 0.0206 - accuracy: 0.9904\n",
            "Epoch 98/200\n",
            "104/104 [==============================] - 0s 96us/step - loss: 0.0206 - accuracy: 0.9904\n",
            "Epoch 99/200\n",
            "104/104 [==============================] - 0s 100us/step - loss: 0.0206 - accuracy: 0.9904\n",
            "Epoch 100/200\n",
            "104/104 [==============================] - 0s 103us/step - loss: 0.0205 - accuracy: 0.9904\n",
            "Epoch 101/200\n",
            "104/104 [==============================] - 0s 101us/step - loss: 0.0205 - accuracy: 0.9904\n",
            "Epoch 102/200\n",
            "104/104 [==============================] - 0s 98us/step - loss: 0.0205 - accuracy: 0.9904\n",
            "Epoch 103/200\n",
            "104/104 [==============================] - 0s 93us/step - loss: 0.0205 - accuracy: 0.9904\n",
            "Epoch 104/200\n",
            "104/104 [==============================] - 0s 95us/step - loss: 0.0205 - accuracy: 0.9904\n",
            "Epoch 105/200\n",
            "104/104 [==============================] - 0s 94us/step - loss: 0.0205 - accuracy: 0.9904\n",
            "Epoch 106/200\n",
            "104/104 [==============================] - 0s 84us/step - loss: 0.0205 - accuracy: 0.9904\n",
            "Epoch 107/200\n",
            "104/104 [==============================] - 0s 91us/step - loss: 0.0204 - accuracy: 0.9904\n",
            "Epoch 108/200\n",
            "104/104 [==============================] - 0s 79us/step - loss: 0.0205 - accuracy: 0.9904\n",
            "Epoch 109/200\n",
            "104/104 [==============================] - 0s 83us/step - loss: 0.0205 - accuracy: 0.9904\n",
            "Epoch 110/200\n",
            "104/104 [==============================] - 0s 131us/step - loss: 0.0204 - accuracy: 0.9904\n",
            "Epoch 111/200\n",
            "104/104 [==============================] - 0s 94us/step - loss: 0.0204 - accuracy: 0.9904\n",
            "Epoch 112/200\n",
            "104/104 [==============================] - 0s 85us/step - loss: 0.0204 - accuracy: 0.9904\n",
            "Epoch 113/200\n",
            "104/104 [==============================] - 0s 96us/step - loss: 0.0205 - accuracy: 0.9904\n",
            "Epoch 114/200\n",
            "104/104 [==============================] - 0s 96us/step - loss: 0.0203 - accuracy: 0.9904\n",
            "Epoch 115/200\n",
            "104/104 [==============================] - 0s 88us/step - loss: 0.0203 - accuracy: 0.9904\n",
            "Epoch 116/200\n",
            "104/104 [==============================] - 0s 96us/step - loss: 0.0204 - accuracy: 0.9904\n",
            "Epoch 117/200\n",
            "104/104 [==============================] - 0s 93us/step - loss: 0.0203 - accuracy: 0.9904\n",
            "Epoch 118/200\n",
            "104/104 [==============================] - 0s 99us/step - loss: 0.0202 - accuracy: 0.9904\n",
            "Epoch 119/200\n",
            "104/104 [==============================] - 0s 108us/step - loss: 0.0202 - accuracy: 0.9904\n",
            "Epoch 120/200\n",
            "104/104 [==============================] - 0s 86us/step - loss: 0.0202 - accuracy: 0.9904\n",
            "Epoch 121/200\n",
            "104/104 [==============================] - 0s 91us/step - loss: 0.0199 - accuracy: 0.9904\n",
            "Epoch 122/200\n",
            "104/104 [==============================] - 0s 89us/step - loss: 0.0203 - accuracy: 0.9904\n",
            "Epoch 123/200\n",
            "104/104 [==============================] - 0s 76us/step - loss: 0.0202 - accuracy: 0.9904\n",
            "Epoch 124/200\n",
            "104/104 [==============================] - 0s 109us/step - loss: 0.0202 - accuracy: 0.9904\n",
            "Epoch 125/200\n",
            "104/104 [==============================] - 0s 95us/step - loss: 0.0202 - accuracy: 0.9904\n",
            "Epoch 126/200\n",
            "104/104 [==============================] - 0s 89us/step - loss: 0.0203 - accuracy: 0.9904\n",
            "Epoch 127/200\n",
            "104/104 [==============================] - 0s 85us/step - loss: 0.0202 - accuracy: 0.9904\n",
            "Epoch 128/200\n",
            "104/104 [==============================] - 0s 83us/step - loss: 0.0202 - accuracy: 0.9904\n",
            "Epoch 129/200\n",
            "104/104 [==============================] - 0s 97us/step - loss: 0.0201 - accuracy: 0.9904\n",
            "Epoch 130/200\n",
            "104/104 [==============================] - 0s 96us/step - loss: 0.0201 - accuracy: 0.9904\n",
            "Epoch 131/200\n",
            "104/104 [==============================] - 0s 92us/step - loss: 0.0200 - accuracy: 0.9904\n",
            "Epoch 132/200\n",
            "104/104 [==============================] - 0s 114us/step - loss: 0.0200 - accuracy: 0.9904\n",
            "Epoch 133/200\n",
            "104/104 [==============================] - 0s 83us/step - loss: 0.0200 - accuracy: 0.9904\n",
            "Epoch 134/200\n",
            "104/104 [==============================] - 0s 96us/step - loss: 0.0200 - accuracy: 0.9904\n",
            "Epoch 135/200\n",
            "104/104 [==============================] - 0s 85us/step - loss: 0.0200 - accuracy: 0.9904\n",
            "Epoch 136/200\n",
            "104/104 [==============================] - 0s 98us/step - loss: 0.0199 - accuracy: 0.9904\n",
            "Epoch 137/200\n",
            "104/104 [==============================] - 0s 119us/step - loss: 0.0199 - accuracy: 0.9904\n",
            "Epoch 138/200\n",
            "104/104 [==============================] - 0s 88us/step - loss: 0.0199 - accuracy: 0.9904\n",
            "Epoch 139/200\n",
            "104/104 [==============================] - 0s 88us/step - loss: 0.0199 - accuracy: 0.9904\n",
            "Epoch 140/200\n",
            "104/104 [==============================] - 0s 90us/step - loss: 0.0199 - accuracy: 0.9904\n",
            "Epoch 141/200\n",
            "104/104 [==============================] - 0s 98us/step - loss: 0.0197 - accuracy: 0.9904\n",
            "Epoch 142/200\n",
            "104/104 [==============================] - 0s 113us/step - loss: 0.0199 - accuracy: 0.9904\n",
            "Epoch 143/200\n",
            "104/104 [==============================] - 0s 151us/step - loss: 0.0199 - accuracy: 0.9904\n",
            "Epoch 144/200\n",
            "104/104 [==============================] - 0s 122us/step - loss: 0.0200 - accuracy: 0.9904\n",
            "Epoch 145/200\n",
            "104/104 [==============================] - 0s 101us/step - loss: 0.0202 - accuracy: 1.0000\n",
            "Epoch 146/200\n",
            "104/104 [==============================] - 0s 85us/step - loss: 0.0206 - accuracy: 1.0000\n",
            "Epoch 147/200\n",
            "104/104 [==============================] - 0s 102us/step - loss: 0.0206 - accuracy: 1.0000\n",
            "Epoch 148/200\n",
            "104/104 [==============================] - 0s 101us/step - loss: 0.0205 - accuracy: 1.0000\n",
            "Epoch 149/200\n",
            "104/104 [==============================] - 0s 84us/step - loss: 0.0205 - accuracy: 1.0000\n",
            "Epoch 150/200\n",
            "104/104 [==============================] - 0s 96us/step - loss: 0.0202 - accuracy: 1.0000\n",
            "Epoch 151/200\n",
            "104/104 [==============================] - 0s 95us/step - loss: 0.0201 - accuracy: 1.0000\n",
            "Epoch 152/200\n",
            "104/104 [==============================] - 0s 97us/step - loss: 0.0200 - accuracy: 1.0000\n",
            "Epoch 153/200\n",
            "104/104 [==============================] - 0s 100us/step - loss: 0.0200 - accuracy: 0.9904\n",
            "Epoch 154/200\n",
            "104/104 [==============================] - 0s 123us/step - loss: 0.0198 - accuracy: 0.9904\n",
            "Epoch 155/200\n",
            "104/104 [==============================] - 0s 108us/step - loss: 0.0197 - accuracy: 0.9904\n",
            "Epoch 156/200\n",
            "104/104 [==============================] - 0s 135us/step - loss: 0.0198 - accuracy: 0.9904\n",
            "Epoch 157/200\n",
            "104/104 [==============================] - 0s 86us/step - loss: 0.0197 - accuracy: 0.9904\n",
            "Epoch 158/200\n",
            "104/104 [==============================] - 0s 88us/step - loss: 0.0197 - accuracy: 0.9904\n",
            "Epoch 159/200\n",
            "104/104 [==============================] - 0s 89us/step - loss: 0.0196 - accuracy: 0.9904\n",
            "Epoch 160/200\n",
            "104/104 [==============================] - 0s 90us/step - loss: 0.0196 - accuracy: 0.9904\n",
            "Epoch 161/200\n",
            "104/104 [==============================] - 0s 100us/step - loss: 0.0196 - accuracy: 0.9904\n",
            "Epoch 162/200\n",
            "104/104 [==============================] - 0s 97us/step - loss: 0.0198 - accuracy: 0.9904\n",
            "Epoch 163/200\n",
            "104/104 [==============================] - 0s 94us/step - loss: 0.0196 - accuracy: 0.9904\n",
            "Epoch 164/200\n",
            "104/104 [==============================] - 0s 85us/step - loss: 0.0196 - accuracy: 0.9904\n",
            "Epoch 165/200\n",
            "104/104 [==============================] - 0s 104us/step - loss: 0.0195 - accuracy: 0.9904\n",
            "Epoch 166/200\n",
            "104/104 [==============================] - 0s 112us/step - loss: 0.0195 - accuracy: 0.9904\n",
            "Epoch 167/200\n",
            "104/104 [==============================] - 0s 94us/step - loss: 0.0196 - accuracy: 0.9904\n",
            "Epoch 168/200\n",
            "104/104 [==============================] - 0s 100us/step - loss: 0.0195 - accuracy: 0.9904\n",
            "Epoch 169/200\n",
            "104/104 [==============================] - 0s 98us/step - loss: 0.0195 - accuracy: 0.9904\n",
            "Epoch 170/200\n",
            "104/104 [==============================] - 0s 90us/step - loss: 0.0195 - accuracy: 0.9904\n",
            "Epoch 171/200\n",
            "104/104 [==============================] - 0s 91us/step - loss: 0.0195 - accuracy: 0.9904\n",
            "Epoch 172/200\n",
            "104/104 [==============================] - 0s 111us/step - loss: 0.0195 - accuracy: 0.9904\n",
            "Epoch 173/200\n",
            "104/104 [==============================] - 0s 88us/step - loss: 0.0195 - accuracy: 0.9904\n",
            "Epoch 174/200\n",
            "104/104 [==============================] - 0s 113us/step - loss: 0.0195 - accuracy: 0.9904\n",
            "Epoch 175/200\n",
            "104/104 [==============================] - 0s 93us/step - loss: 0.0195 - accuracy: 0.9904\n",
            "Epoch 176/200\n",
            "104/104 [==============================] - 0s 88us/step - loss: 0.0194 - accuracy: 0.9904\n",
            "Epoch 177/200\n",
            "104/104 [==============================] - 0s 83us/step - loss: 0.0194 - accuracy: 0.9904\n",
            "Epoch 178/200\n",
            "104/104 [==============================] - 0s 205us/step - loss: 0.0194 - accuracy: 0.9904\n",
            "Epoch 179/200\n",
            "104/104 [==============================] - 0s 133us/step - loss: 0.0195 - accuracy: 0.9904\n",
            "Epoch 180/200\n",
            "104/104 [==============================] - 0s 109us/step - loss: 0.0194 - accuracy: 0.9904\n",
            "Epoch 181/200\n",
            "104/104 [==============================] - 0s 99us/step - loss: 0.0194 - accuracy: 0.9904\n",
            "Epoch 182/200\n",
            "104/104 [==============================] - 0s 101us/step - loss: 0.0194 - accuracy: 0.9904\n",
            "Epoch 183/200\n",
            "104/104 [==============================] - 0s 98us/step - loss: 0.0193 - accuracy: 0.9904\n",
            "Epoch 184/200\n",
            "104/104 [==============================] - 0s 94us/step - loss: 0.0195 - accuracy: 0.9904\n",
            "Epoch 185/200\n",
            "104/104 [==============================] - 0s 102us/step - loss: 0.0193 - accuracy: 0.9904\n",
            "Epoch 186/200\n",
            "104/104 [==============================] - 0s 85us/step - loss: 0.0193 - accuracy: 0.9904\n",
            "Epoch 187/200\n",
            "104/104 [==============================] - 0s 89us/step - loss: 0.0193 - accuracy: 0.9904\n",
            "Epoch 188/200\n",
            "104/104 [==============================] - 0s 104us/step - loss: 0.0192 - accuracy: 0.9904\n",
            "Epoch 189/200\n",
            "104/104 [==============================] - 0s 90us/step - loss: 0.0193 - accuracy: 0.9904\n",
            "Epoch 190/200\n",
            "104/104 [==============================] - 0s 90us/step - loss: 0.0194 - accuracy: 0.9904\n",
            "Epoch 191/200\n",
            "104/104 [==============================] - 0s 91us/step - loss: 0.0195 - accuracy: 0.9904\n",
            "Epoch 192/200\n",
            "104/104 [==============================] - 0s 87us/step - loss: 0.0192 - accuracy: 0.9904\n",
            "Epoch 193/200\n",
            "104/104 [==============================] - 0s 125us/step - loss: 0.0192 - accuracy: 0.9904\n",
            "Epoch 194/200\n",
            "104/104 [==============================] - 0s 93us/step - loss: 0.0193 - accuracy: 0.9904\n",
            "Epoch 195/200\n",
            "104/104 [==============================] - 0s 89us/step - loss: 0.0193 - accuracy: 0.9904\n",
            "Epoch 196/200\n",
            "104/104 [==============================] - 0s 86us/step - loss: 0.0192 - accuracy: 0.9904\n",
            "Epoch 197/200\n",
            "104/104 [==============================] - 0s 106us/step - loss: 0.0192 - accuracy: 0.9904\n",
            "Epoch 198/200\n",
            "104/104 [==============================] - 0s 100us/step - loss: 0.0193 - accuracy: 0.9904\n",
            "Epoch 199/200\n",
            "104/104 [==============================] - 0s 97us/step - loss: 0.0191 - accuracy: 0.9904\n",
            "Epoch 200/200\n",
            "104/104 [==============================] - 0s 95us/step - loss: 0.0192 - accuracy: 0.9904\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7fba8ac1a6d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LKbRskr84iX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        },
        "outputId": "b50079f5-03ae-4925-8501-6cae04b449ce"
      },
      "source": [
        "Y_pred = model.predict(X_test)\n",
        "Y_pred"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.47890875e-06, 2.72191405e-01, 7.27806151e-01],\n",
              "       [7.18202182e-06, 2.97179655e-03, 9.97021019e-01],\n",
              "       [3.24026361e-09, 1.00000000e+00, 1.62010405e-08],\n",
              "       [9.03997091e-08, 9.99999881e-01, 4.14064836e-08],\n",
              "       [9.99859214e-01, 1.40737000e-04, 1.77902330e-17],\n",
              "       [1.03421620e-11, 1.21710173e-07, 9.99999881e-01],\n",
              "       [3.22338209e-08, 5.12454826e-05, 9.99948740e-01],\n",
              "       [2.82680936e-04, 9.99044359e-01, 6.72934169e-04],\n",
              "       [7.89720218e-08, 4.96863067e-01, 5.03136873e-01],\n",
              "       [2.67559942e-02, 8.50144863e-01, 1.23099118e-01],\n",
              "       [9.99853015e-01, 1.47019469e-04, 6.08991005e-18],\n",
              "       [9.99496341e-01, 5.03658608e-04, 2.63738240e-16],\n",
              "       [9.77869058e-05, 9.97369885e-01, 2.53235688e-03],\n",
              "       [9.94534492e-01, 5.46552800e-03, 4.10525000e-16],\n",
              "       [9.99990463e-01, 9.58143573e-06, 2.69070645e-18],\n",
              "       [2.63594429e-05, 2.87382871e-01, 7.12590694e-01],\n",
              "       [1.44205918e-08, 2.80063232e-05, 9.99971986e-01],\n",
              "       [3.03436173e-05, 9.99430001e-01, 5.39618602e-04],\n",
              "       [1.00000000e+00, 4.94086123e-08, 1.57396899e-18],\n",
              "       [1.00000000e+00, 6.63844535e-11, 1.25373261e-20],\n",
              "       [2.17522192e-03, 9.97824788e-01, 8.94488815e-16],\n",
              "       [9.99853015e-01, 1.47019469e-04, 6.08991005e-18],\n",
              "       [5.54933969e-04, 7.51224935e-01, 2.48220086e-01],\n",
              "       [9.99984980e-01, 1.49635471e-05, 3.79113270e-15],\n",
              "       [2.08449535e-04, 9.52252448e-01, 4.75391410e-02],\n",
              "       [4.31805383e-04, 9.99491930e-01, 7.62428172e-05],\n",
              "       [6.76246011e-04, 9.65782285e-01, 3.35414298e-02],\n",
              "       [9.99999881e-01, 1.61358216e-07, 8.22124574e-19],\n",
              "       [1.00000000e+00, 1.67823852e-10, 1.93887517e-18],\n",
              "       [8.89846096e-12, 1.08712264e-07, 9.99999881e-01],\n",
              "       [9.99998689e-01, 1.31585045e-06, 1.93643333e-18],\n",
              "       [6.18794229e-06, 9.99993801e-01, 4.02451299e-08],\n",
              "       [5.82583198e-05, 9.99282181e-01, 6.59596641e-04],\n",
              "       [1.04950881e-03, 1.21691249e-01, 8.77259254e-01],\n",
              "       [1.00000000e+00, 5.05749227e-11, 4.29036870e-20],\n",
              "       [2.63840029e-05, 4.22564484e-02, 9.57717121e-01],\n",
              "       [3.21733432e-06, 1.62628444e-03, 9.98370469e-01],\n",
              "       [1.82041926e-09, 9.99999881e-01, 8.38427354e-08],\n",
              "       [2.42220252e-04, 5.95957279e-01, 4.03800577e-01],\n",
              "       [9.99990225e-01, 9.76200954e-06, 6.11528423e-18],\n",
              "       [3.32709106e-07, 2.95884209e-04, 9.99703705e-01],\n",
              "       [9.99999881e-01, 6.18573708e-08, 5.32576205e-19],\n",
              "       [1.45730405e-06, 9.99998569e-01, 1.02229212e-08],\n",
              "       [1.43399550e-08, 2.78886000e-05, 9.99972105e-01],\n",
              "       [1.72718284e-08, 3.20710533e-05, 9.99967933e-01]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqyHO9D59fqH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "y_test_class= np.argmax(Y_test,axis=1)\n",
        "y_pred_class= np.argmax(Y_pred,axis=1)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzm3HCK594Sv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test_class,y_pred_class)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPB0Lj0B-dO3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "390bf85b-1ee6-4a94-dc8d-7ae8cb551643"
      },
      "source": [
        "sns.heatmap(cm,annot=True)\n",
        "plt.savefig('test_data.png')"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTHToKus-duH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a742cb46-90a5-4f5e-baf2-ab9199f2f598"
      },
      "source": [
        "a = 15+15+13\n",
        "f = 2 \n",
        "b = a + f\n",
        "print(b,a/b)\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "45 0.9555555555555556\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKnhHofE-xGe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}